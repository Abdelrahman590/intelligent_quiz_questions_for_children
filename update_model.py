from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM
import json
import re
import os
os.environ['HF_HOME'] = 'D:/huggingface_cache'


# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØµÙŠØ§ØºØ©
def get_paraphraser():
    try:
        return pipeline(
            "text2text-generation",
            model="humarin/chatgpt_paraphraser_on_T5_base",
            device=0,
            max_length=60
        )
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØµÙŠØ§ØºØ©: {e}")
        return None

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø³ÙŠØ§Ù‚ÙŠØ© (NLLB)
nllb_model_name = "facebook/nllb-200-distilled-600M"
nllb_tokenizer = AutoTokenizer.from_pretrained(nllb_model_name)
nllb_model = AutoModelForSeq2SeqLM.from_pretrained(nllb_model_name)

# ØªØ±Ø¬Ù…Ø© Ø°ÙƒÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… NLLB
def smart_translate(text, src_lang="eng_Latn", tgt_lang="arb_Arab"):
    try:
        inputs = nllb_tokenizer(text, return_tensors="pt", src_lang=src_lang)
        translated_tokens = nllb_model.generate(
            **inputs,
            forced_bos_token_id=nllb_tokenizer.lang_code_to_id[tgt_lang],
            max_length=60
        )
        return nllb_tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ NLLB: {e}")
        return text

# ØªØµÙ†ÙŠÙ Ø§Ù„Ù†Øµ
def classify_text(text):
    if re.fullmatch(r'[A-Za-z]', text.strip()):
        return "letter"
    elif len(text.strip().split()) == 1:
        return "word"
    else:
        return "sentence"

# ØªØ±Ø¬Ù…Ø© Ø°ÙƒÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ù†Øµ
def context_aware_translate(text):
    text_type = classify_text(text)
    if text_type == "letter":
        return {
            "A": "Ø£", "B": "Ø¨", "C": "Ø¬", "D": "Ø¯", "E": "Ù‡Ù€",
            "F": "Ù", "G": "Ø¬", "H": "Ù‡Ù€", "I": "ÙŠ", "J": "Ø¬",
            "K": "Ùƒ", "L": "Ù„", "M": "Ù…", "N": "Ù†", "O": "Ùˆ",
            "P": "Ø¨", "Q": "Ù‚", "R": "Ø±", "S": "Ø³", "T": "Øª",
            "U": "Ø¹", "V": "Ù", "W": "Ùˆ", "X": "Ø¥ÙƒØ³", "Y": "ÙŠ", "Z": "Ø²"
        }.get(text.upper(), text)
    else:
        return smart_translate(text)

# ØªØ¨Ø³ÙŠØ· Ù„ØºÙˆÙŠ Ù„Ù„Ø£Ø·ÙØ§Ù„
def simplify_for_children(text):
    simplifications = {
        "Ø§Ù„ØªÙŠ": "Ø§Ù„Ù„ÙŠ",
        "ØªØ³ØªØ·ÙŠØ¹": "ØªÙ‚Ø¯Ø±",
        "ÙŠØ³ØªØ·ÙŠØ¹": "ÙŠÙ‚Ø¯Ø±",
        "Ø°Ù„Ùƒ": "Ø¯Ù‡",
        "ØªÙ„Ùƒ": "Ø¯ÙŠ",
        "Ø§Ù„Ø·ÙÙ„": "Ø§Ù„ÙˆÙ„Ø¯",
        "Ø§Ù„Ø·ÙÙ„Ø©": "Ø§Ù„Ø¨Ù†Øª",
        "Ø±Ø³Ø§Ù„Ø©": "Ø­Ø±Ù",
        "Ø¬Ù…Ù„Ø©": "Ø¬ÙÙ…Ù„Ù‡",
        "Ø£ÙŠ": "Ø¥ÙŠÙ‡",
        "Ù…Ø§ Ù‡ÙŠ": "Ø¥ÙŠÙ‡ Ù‡ÙŠ",
        "Ù…Ø§ Ù‡Ùˆ": "Ø¥ÙŠÙ‡ Ù‡Ùˆ"
    }
    for k, v in simplifications.items():
        text = text.replace(k, v)
    return text

# Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„
def paraphrase_question(paraphraser, question, num_versions=3):
    if not paraphraser:
        return [question] * (num_versions + 1)
    versions = [question]
    try:
        paraphrases = paraphraser(
            f"paraphrase: {question}",
            num_return_sequences=min(num_versions * 2, 5),
            num_beams=5,
            temperature=0.7,
            repetition_penalty=2.5
        )
        unique_paraphrases = set()
        for p in paraphrases:
            text = p['generated_text'].strip()
            if (
                text.lower() != question.lower() and
                len(text.split()) > 3 and
                '?' in text
            ):
                unique_paraphrases.add(text)
        versions.extend(list(unique_paraphrases)[:num_versions])
        return versions
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØµÙŠØ§ØºØ©: {e}")
        return [question] * (num_versions + 1)

# Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©
def enhance_question_quality(input_file, output_file):
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        paraphraser_model = get_paraphraser()

        for i, item in enumerate(data):
            item['versions'] = paraphrase_question(paraphraser_model, item['question'])

            item['versions_ar'] = [
                simplify_for_children(context_aware_translate(v))
                for v in item['versions']
            ]

            item['choices_ar'] = [
                simplify_for_children(context_aware_translate(c))
                for c in item['choices']
            ]

            item['answer_ar'] = simplify_for_children(context_aware_translate(item['answer']))

            item['category_ar'] = simplify_for_children(context_aware_translate(
                item['category'] if item['category'] else "Ø¹Ø§Ù…"
            ))

            print(f"âœ… ØªÙ… ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø³Ø¤Ø§Ù„ {i+1}/{len(data)}")

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"ğŸ‰ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ: {output_file}")
        return True

    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {e}")
        return False

# Ø§Ù„ØªØ´ØºÙŠÙ„
if __name__ == "__main__":
    input_path = "D:\\company\\En_questions.json"
    output_path = "D:\\company\\enhanced_questions_final.json"
    enhance_question_quality(input_path, output_path)
